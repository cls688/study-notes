# 搭建集群

## 准备虚拟机

使用VMware安装一台虚拟机

创建一个hadoop文件夹

在里面复制三次已经安装好的虚拟机

分别重命名为node1、node2、node3

用VMware打开`CentOS 7 64 位.vmx`文件

![image-20211102161026966](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102161026966.png)

VMware中打开的三台虚拟机重命名为node1、node2、node3

![image-20211102161431791](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102161431791.png)

## 设置网关

1.确保VMware服务全部启动

![image-20211102161811038](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102162020012.png)

2.确认VMware网关地址

![image-20211102161932530](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102162112526.png)

![image-20211102162020012](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102161932530.png)

![image-20211102162112526](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102161811038.png)

在本地网络适配器中设置

<img src="https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102162427615.png" alt="image-20211102162427615"  />

![image-20211102162601025](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102162735336.png)

填写内容与VMware中NAT设置一致，**IP地址不能用网关地址**

![image-20211102162735336](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211102162601025.png)

## 更改mac地址和IP

```shell
cd /etc/udev/rules.d/
vim 70(按键盘TAb补全)#修改mac和网卡名称（一般是ens33）
```

```shell
cd /etc/sysconfig/network-scripts/
vim ifcfg-e #(按tab补全)一般是ens33
```

修改和增加内容

```shell
BOOTPROTO=static
ONBOOT=yes
DEVICE=ens33
HWADDR=mac地址
IPADDR=192.168.XXX.XXX
GATEWAY=192.168.XXX.XXX#网关地址
NETMASK=255.255.255.0
DNS1=8.8.8.8
```

## 修改主机名

```shell
vim /etc/sysconfig/network
```

内容

```shell
HOSTNAME=node1
```

## 设置IP和域名

```shell
vim /etc/hosts
```

```shell
192.168.XXX.110 node1 node1.hadoop.com
192.168.XXX.120 node2 node2.hadoop.com
192.168.XXX.130 node3 node3.hadoop.com
```

重启

```shell
reboot
```

## 关闭防火墙和selinux

查看防火墙状态

```shell
firewall-cmd --state
```

关闭服务

```shell
systemctl stop firewalld.service
```

禁止开机自启

```shell
systemctl disable firewalld.service
```

关闭selinux

```shell
vim /etc/sysconfig/selinux
```

修改

```shell
SELINUX=disabled
```

## 免密登录

生成密钥对

```shell
ssh-keygen -t rsa
```

按三下回车

分发公钥给第一台机器，三台机器都要执行

```shell
ssh-copy-id node1
```

分发第一台机器的认证给其他两台机器

```shell
scp /root/.ssh/authorized_keys node2:/root/.ssh
scp /root/.ssh/authorized_keys node3:/root/.ssh
```

## 时钟同步

安装ntp

```shell
yum install -y ntp
```

启动定时任务

```shell
crontab -e
```

在出现的界面中输入

```shell
*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com;
```



# jdk环境

## 1.查看自带的openjdk并卸载

（--nodeps不检查）

```shell
rpm -qa | grep java

rpm -e  java-*** --nodeps
```

## 2.创建安装目录

```shell
mkdir -p /export/softwares  #软件包存放目录
mkdir -p /export/servers #安装目录
```

## 3.上传并解压

```shell
yum -y install lrzsz #安装上传工具
rz -E #上传文件
tar -xvf jdk -C ../servers/
```

## 4.分发

在当前目录下

```shell
scp -r jdk1.8.0_301/ node2:$PWD
```

## 5.配置环境变量

```shell
vim /etc/profile
```

添加内容

```shell
export JAVA_HOME=/export/servers/jdk1.8.0_301
export PATH=:$JAVA_HOME/bin:$PATH
```

文件生效

```shell
source /etc/profile
```



# zookeeper

## 安装

### 1.下载

zookeeper下载网址**http://archive.apache.org/dist/zookeeper/**

### 2.上传

上传至Linux中**/export/softwares**

### 3.解压

```shell
cd /export/softwares

tar -xvf zoookeeper-3.4.9.tar.gz -C ../servers/
```

### 4.修改配置文件

第一台机器修改

```shell
cd /export/servers/zookeeper-3.4.9/conf/

cp zoo_sample.cfg zoo.cfg

mkdir -p /export/servers/zookeeper-3.4.9/zkdatas/

vim zoo.cfg
```

添加内容

```
dataDir=/export/servers/zookeeper-3.4.9/zkdatas
# 保留多少个快照
autopurge.snapRetainCount=3
# 日志多少小时清理一次
autopurge.purgeInterval=1
# 集群中服务器地址
server.1=node1:2888:3888
server.2=node2:2888:3888
server.3=node3:2888:3888
```

### 5.添加myid配置

在第一台机器的`/export/servers/zookeeper-3.4.9/zkdatas/`这个路径下创建一个文件，

文件名为*myid* ,文件内容为**1**

```shell
echo 1 > /export/servers/zookeeper-3.4.9/zkdatas/myid
```

### 6.分发安装包并修改myid值

在第一台机器上执行

```shell
scp -r /export/servers/zookeeper-3.4.9/ node2:/export/servers/

scp -r /export/servers/zookeeper-3.4.9/ node3:/export/servers/
```

第二台机器上修改myid的值为2

```shell
echo 2 > /export/servers/zookeeper-3.4.9/zkdatas/myid
```

第三台机器上修改myid的值为2

```shell
echo 3 > /export/servers/zookeeper-3.4.9/zkdatas/myid
```

### 7.启动服务

三台机器启动服务

```shell
/export/servers/zookeeper-3.4.9/bin/zkServer.sh start
```

查看状态

```shell
/export/servers/zookeeper-3.4.9/bin/zkServer.sh status
```

启动Hadoop集群

```
http://node1:50070/explorer.html#/
http://node1:8088/cluster
http://node1:19888/jobhistory
```

# 安装Hadoop

### 1、上传解压文件

appache-before-hadoop-2.7.5.tar.gz

### 2、notepad++连接虚拟机

插件 ->下载nppFTP

配置信息

![image-20211123142617409](https://note-1010.oss-cn-beijing.aliyuncs.com/img/image-20211123142617409.png)

### 3、修改Hadoop配置文件

###### (1)core-site.xml

```xml
<configuration>
 <property>
 <name>fs.default.name</name>
 <value>hdfs://node1:8020</value>
 </property>
 <property>
 <name>hadoop.tmp.dir</name>
 <value>/export/servers/hadoop-2.7.5/hadoopDatas/tempDatas</value>
 </property>
 <!-- 缓冲区大小，实际工作中根据服务器性能动态调整 -->
 <property>
 <name>io.file.buffer.size</name>
 <value>4096</value>
 </property>
 <!-- 开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 -->
 <property>
 <name>fs.trash.interval</name>
 <value>10080</value>
 </property>
</configuration>
```

###### (2)hdfs-site.xml

```xml
<configuration>
 <property>
 <name>dfs.namenode.secondary.http-address</name>
 <value>node1:50090</value>
 </property>
 <property>
 <name>dfs.namenode.http-address</name>
 <value>node1:50070</value>
 </property>
 <property>
 <name>dfs.namenode.name.dir</name>
 <value>file:///export/servers/hadoop-2.7.5/hadoopDatas/namenodeDatas,file:///export/servers/hadoop-2.7.5/hadoopDatas/namenodeDatas2</value>
     </property>
 <!-- 定义dataNode数据存储的节点位置，实际工作中，一般先确定磁盘的挂载目录，然后
多个目录用，进行分割 -->
 <property>
 <name>dfs.datanode.data.dir</name>
 <value>file:///export/servers/hadoop-2.7.5/hadoopDatas/datanodeDatas,file:///export/servers/hadoop-2.7.5/hadoopDatas/datanodeDatas2</value>
 </property>
    
 <property>
 <name>dfs.namenode.edits.dir</name>
 <value>file:///export/servers/hadoop-2.7.5/hadoopDatas/nn/edits</value>
 </property>
 <property>
 <name>dfs.namenode.checkpoint.dir</name>
 <value>file:///export/servers/hadoop-2.7.5/hadoopDatas/snn/name</value>
 </property>
    
 <property>
 <name>dfs.namenode.checkpoint.edits.dir</name>
 <value>file:///export/servers/hadoop-2.7.5/hadoopDatas/dfs/snn/edits</value>
 </property>
 <property>
 <name>dfs.replication</name>
 <value>3</value>
 </property>
 <property>
 <name>dfs.permissions</name>
 <value>false</value>
 </property>
    <property>
 <name>dfs.blocksize</name>
        <value>134217728</value>
 </property>
</configuration>
```

###### (3)hadoop-env.sh

```sh
export JAVA_HOME=/export/servers/jdk1.8.0_301
```

###### (4)mapred-site.xml

```xml
<configuration>
    
 <property>
 <name>mapreduce.job.ubertask.enable</name>
 <value>true</value>
 </property>
 <property>
 <name>mapreduce.jobhistory.address</name>
 <value>node1:10020</value>
 </property>
 <property>
 <name>mapreduce.jobhistory.webapp.address</name>
 <value>node1:19888</value>
 </property>
</configuration>
```

###### (5)yarn-site.xml

```xml
<configuration>
 <property>
 <name>yarn.resourcemanager.hostname</name>
 <value>node1</value>
 </property>
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
 
 <property>
 <name>yarn.log-aggregation-enable</name>
 <value>true</value>
 </property>
 <property>
 <name>yarn.log-aggregation.retain-seconds</name>
 <value>604800</value>
 </property>
 <property>    
 <name>yarn.nodemanager.resource.memory-mb</name>    
 <value>20480</value>
 </property>
 <property>  
       <name>yarn.scheduler.minimum-allocation-mb</name>
         <value>2048</value>
 </property>
 <property>
 <name>yarn.nodemanager.vmem-pmem-ratio</name>
 <value>2.1</value>
 </property>
</configuration>
```

###### (6)mapred-env.sh

```sh
export JAVA_HOME=/export/servers/jdk1.8.0_301
```

###### (7)slaves

```
node1
node2
node3
```

###### (8)第一台机器执行

```shell
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/tempDatas
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/namenodeDatas
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/namenodeDatas2
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/datanodeDatas
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/datanodeDatas2
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/nn/edits
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/snn/name
mkdir -p /export/servers/hadoop-2.7.5/hadoopDatas/dfs/snn/edits
```

###### (9)分发

```shell
cd /export/servers/
scp -r hadoop-2.7.5 node2:$PWD
scp -r hadoop-2.7.5 node3:$PWD
```

### 4、配置环境变量

三台机器执行

```shell
vim /etc/profile
```

```shell
export HADOOP_HOME=/export/servers/hadoop-2.7.5
export PATH=:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```

文件生效

```shell
source /etc/profile
```

### 5、启动集群

第一次启动要格式化namenode

```shell
cd /export/servers/hadoop-2.7.5/
bin/hdfs namenode -format
sbin/start-dfs.sh
sbin/start-yarn.sh
sbin/mr-jobhistory-daemon.sh start historyserver
```

三个端口查看界面

**http://node1:50070/explorer.html#/** 查看hdfs

**http://node1:8088/cluster** 查看yarn集群

**http://node1:19888/jobhistory** 查看历史完成的任务

# hdfs命令

### ls

```shell
hdfs dfs -ls /
```

### mkdir

```shell
hdfs dfs -mkdir /
```

### put

将单个的源文件src或者多个源文件srcs从本地文件系统拷贝到目标文件系统中（<dst>对应的路径）。也可以从标准输入中读取输入，写入目标文件系统中

```shell
hdfs dfs -put <localsrc > ... <dst>
```

### moveFromLocal

和put命令类似，但是源文件localsrc拷贝之后自身被删除

```shell
hdfs dfs -moveFromLocal <localsrc>   <dst>
```

### get

将文件拷贝到本地文件系统。 CRC 校验失败的文件通过-ignorecrc选项拷贝。 文件和CRC校验和可以通过-CRC选项拷贝

```shell
hdfs dfs  -get [-ignorecrc ] [-crc] <src> <localdst>
```

### mv

将hdfs上的文件从原路径移动到目标路径（移动之后文件删除），该命令不能夸文件系统

```shell
hdfs dfs -mv /dir1/a.txt /dir2
```

### rm

删除参数指定的文件，参数可以有多个。  此命令只删除文件和非空目录。

如果指定-skipTrash选项，那么在回收站可用的情况下，该选项将跳过回收站而直接删除文件；

否则，在回收站可用时，在HDFS Shell 中执行此命令，会将文件暂时放到回收站中。

```shell
hdfs dfs -rm [-r] 【-skipTrash】 URI 【URI 。。。】
```

### cp

将文件拷贝到目标路径中。如果<dest> 为目录的话，可以将多个文件拷贝到该目录下。

-f

选项将覆盖目标，如果它已经存在。

-p

选项将保留文件属性（时间戳、所有权、许可、ACL、XAttr）。

```shell
hdfs  dfs  -cp URI [URI ...] <dest>
```

### cat

将参数所指示的文件内容输出到stdout

```shell
hdfs dfs  -cat URI [uri ...]
```

### chmod

改变文件权限。如果使用 -R 选项，则对整个目录有效递归执行。使用这一命令的用户必须是文件的所属用户，或者超级用户。

```shell
hdfs   dfs  -chmod  [-R]  URI[URI  ...]
```

### chown

改变文件的所属用户和用户组。如果使用 -R 选项，则对整个目录有效递归执行。使用这一命令的用户必须是文件的所属用户，或者超级用户。

```shell
hdfs   dfs  -chown  [-R]  URI[URI  ...]
```

### appendToFile

追加一个或者多个文件到hdfs指定文件中.也可以从命令行读取输入

```shell
hdfs dfs -appendToFile <localsrc> ... <dst>
```

### 总命令

```shell
hdfs dfs
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] <localsrc> ... <dst>]
	[-copyToLocal [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] <path> ...]
	[-cp [-f] [-p | -p[topax]] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] <path> ...]
	[-expunge]
	[-find <path> ... <expression> ...]
	[-get [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] <src> <localdst>]
	[-help [cmd ...]]
	[-ls [-d] [-h] [-R] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touchz <path> ...]
	[-truncate [-w] <length> <path> ...]
	[-usage [cmd ...]]
```

